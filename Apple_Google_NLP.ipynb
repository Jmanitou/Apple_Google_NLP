{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the responses of products displayed at South by South West (SXSW) and seeing which product was seen to be the most favorable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Data Read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import multidict as multidict\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "from os import path\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in tweets from data, about 9000 rows and three columns\n",
    "df = pd.read_csv(\"data/twitter_data.csv\", encoding=\"unicode_escape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropped one tweet that had a NA value (row 6)\n",
    "df = df.loc[df[\"tweet_text\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = RegexpTokenizer(r\"(?u)\\w{3,}\").tokenize(tweet)\n",
    "    tweet = [word for word in tweet if word not in stopwords.words(\"english\")]\n",
    "    tweet = [PorterStemmer().stem(word) for word in tweet]\n",
    "    return tweet\n",
    "\n",
    "df[\"preprocessed_text\"] = [preprocess_text(tweet) for tweet in df[\"tweet_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def company(tweet):\n",
    "    if \"appl\" in tweet or \"iphon\" in tweet or \"ipad\" in tweet:\n",
    "        return \"apple\"\n",
    "    elif \"googl\" in tweet or \"android\" in tweet:\n",
    "        return \"google\"\n",
    "\n",
    "df[\"predict_company\"] = [company(tweet) for tweet in df[\"preprocessed_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directed_at(tweet):\n",
    "    if \"app\" in tweet:\n",
    "        return \"app\"\n",
    "    elif \"ipad\" in tweet:\n",
    "        return \"ipad\"\n",
    "    elif \"iphon\" in tweet:\n",
    "        return \"iphone\"\n",
    "    elif \"android\" in tweet:\n",
    "        return \"android\"\n",
    "    elif \"googl\" in tweet:\n",
    "        return \"google\"\n",
    "\n",
    "df[\"predict_directed\"] = [directed_at(tweet) for tweet in df[\"preprocessed_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apple     5477\n",
       "google    2783\n",
       "Name: predict_company, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"predict_company\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "positive_wordcount = {}\n",
    "for row in df.loc[df['is_there_an_emotion_directed_at_a_brand_or_product'] == \"Positive emotion\"][\"preprocessed_text\"]:\n",
    "    for word in row:\n",
    "        if word in positive_wordcount:\n",
    "            positive_wordcount[word] += 1\n",
    "        else:\n",
    "            positive_wordcount[word] = 1\n",
    "            \n",
    "for key in list(positive_wordcount.keys()):\n",
    "    if positive_wordcount[key] < 50:\n",
    "        del positive_wordcount[key]\n",
    "\n",
    "print(len(positive_wordcount))\n",
    "\n",
    "negative_wordcount = {}\n",
    "for row in df.loc[df['is_there_an_emotion_directed_at_a_brand_or_product'] == \"Negative emotion\"][\"preprocessed_text\"]:\n",
    "    for word in row:\n",
    "        if word in negative_wordcount:\n",
    "            negative_wordcount[word] += 1\n",
    "        else:\n",
    "            negative_wordcount[word] = 1\n",
    "            \n",
    "for key in list(negative_wordcount.keys()):\n",
    "    if negative_wordcount[key] < 10:\n",
    "        del negative_wordcount[key]\n",
    "\n",
    "print(len(negative_wordcount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive emotion    1732\n",
       "Negative emotion     196\n",
       "Name: predict_emotion, dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emotion(tweet):\n",
    "    if (\"great\" in tweet or \"awesom\" in tweet or \"like\" in tweet or \"appreci\" in tweet or \"good\" in tweet \n",
    "            or \"beauti\" in tweet or \"smart\" in tweet or \"excit\" in tweet or \"wait\" in tweet or \"best\" in tweet\n",
    "            or \"love\" in tweet or \"nice\" in tweet or \"must\" in tweet or \"enjoy\" in tweet or \"fun\" in tweet\n",
    "            or \"rock\" in tweet or \"cool\" in tweet): #maybe remove like\n",
    "        return \"Positive emotion\"\n",
    "    elif (\"dead\" in tweet or \"insan\" in tweet or \"headach\" in tweet or \"long\" in tweet or \"fail\" in tweet or \"hate\" in tweet\n",
    "            or \"suck\" in tweet or \"fascist\" in tweet or \"fade\" in tweet or \"crashi\" in tweet):\n",
    "        return \"Negative emotion\"\n",
    "    \n",
    "df[\"predict_emotion\"] = [emotion(tweet) for tweet in df[\"preprocessed_text\"]]\n",
    "df[\"predict_emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_normalize(emotion):\n",
    "    if emotion == \"Positive emotion\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def negative_normalize(emotion):        \n",
    "    if emotion == \"Negative emotion\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "df[\"positive\"] = [positive_normalize(emotion) for emotion in df[\"is_there_an_emotion_directed_at_a_brand_or_product\"]]\n",
    "df[\"negative\"] = [negative_normalize(emotion) for emotion in df[\"is_there_an_emotion_directed_at_a_brand_or_product\"]]\n",
    "\n",
    "df[\"predict_positive\"] = [positive_normalize(emotion) for emotion in df[\"predict_emotion\"]]\n",
    "df[\"predict_negative\"] = [negative_normalize(emotion) for emotion in df[\"predict_emotion\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.79      6114\n",
      "           1       0.56      0.32      0.41      2978\n",
      "\n",
      "    accuracy                           0.69      9092\n",
      "   macro avg       0.64      0.60      0.60      9092\n",
      "weighted avg       0.67      0.69      0.67      9092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df[\"positive\"], df[\"predict_positive\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3247145735392881"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(df[\"positive\"], df[\"predict_positive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5583140877598153"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(df[\"positive\"], df[\"predict_positive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      8522\n",
      "           1       0.46      0.16      0.24       570\n",
      "\n",
      "    accuracy                           0.94      9092\n",
      "   macro avg       0.71      0.57      0.60      9092\n",
      "weighted avg       0.92      0.94      0.92      9092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df[\"negative\"], df[\"predict_negative\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15964912280701754"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(df[\"negative\"], df[\"predict_negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4642857142857143"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(df[\"negative\"], df[\"predict_negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad                               946\n",
       "Apple                              661\n",
       "iPad or iPhone App                 470\n",
       "Google                             430\n",
       "iPhone                             297\n",
       "Other Google product or service    293\n",
       "Android App                         81\n",
       "Android                             78\n",
       "Other Apple product or service      35\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"emotion_in_tweet_is_directed_at\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     5801\n",
       "False    3291\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"emotion_in_tweet_is_directed_at\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5388\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"is_there_an_emotion_directed_at_a_brand_or_product\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     7363\n",
       "False    1729\n",
       "Name: predict_emotion, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"predict_emotion\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>predict_company</th>\n",
       "      <th>predict_directed</th>\n",
       "      <th>predict_emotion</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>predict_positive</th>\n",
       "      <th>predict_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[wesley83, iphon, hr, tweet, rise_austin, dead...</td>\n",
       "      <td>apple</td>\n",
       "      <td>iphone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[jessede, know, fludapp, awesom, ipad, iphon, ...</td>\n",
       "      <td>apple</td>\n",
       "      <td>app</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[swonderlin, wait, ipad, also, sale, sxsw]</td>\n",
       "      <td>apple</td>\n",
       "      <td>ipad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[sxsw, hope, year, festiv, crashi, year, iphon...</td>\n",
       "      <td>apple</td>\n",
       "      <td>app</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[sxtxstate, great, stuff, fri, sxsw, marissa, ...</td>\n",
       "      <td>google</td>\n",
       "      <td>google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[ipad, everywher, sxsw, link]</td>\n",
       "      <td>apple</td>\n",
       "      <td>ipad</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[wave, buzz, mention, interrupt, regularli, sc...</td>\n",
       "      <td>google</td>\n",
       "      <td>google</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[googl, zeiger, physician, never, report, pote...</td>\n",
       "      <td>google</td>\n",
       "      <td>google</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[verizon, iphon, custom, complain, time, fell,...</td>\n",
       "      <td>apple</td>\n",
       "      <td>iphone</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[ûârt, mention, googl, test, ûïcheck, offer, s...</td>\n",
       "      <td>google</td>\n",
       "      <td>google</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9092 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0                                      Negative emotion   \n",
       "1                                      Positive emotion   \n",
       "2                                      Positive emotion   \n",
       "3                                      Negative emotion   \n",
       "4                                      Positive emotion   \n",
       "...                                                 ...   \n",
       "9088                                   Positive emotion   \n",
       "9089                 No emotion toward brand or product   \n",
       "9090                 No emotion toward brand or product   \n",
       "9091                 No emotion toward brand or product   \n",
       "9092                 No emotion toward brand or product   \n",
       "\n",
       "                                      preprocessed_text predict_company  \\\n",
       "0     [wesley83, iphon, hr, tweet, rise_austin, dead...           apple   \n",
       "1     [jessede, know, fludapp, awesom, ipad, iphon, ...           apple   \n",
       "2            [swonderlin, wait, ipad, also, sale, sxsw]           apple   \n",
       "3     [sxsw, hope, year, festiv, crashi, year, iphon...           apple   \n",
       "4     [sxtxstate, great, stuff, fri, sxsw, marissa, ...          google   \n",
       "...                                                 ...             ...   \n",
       "9088                      [ipad, everywher, sxsw, link]           apple   \n",
       "9089  [wave, buzz, mention, interrupt, regularli, sc...          google   \n",
       "9090  [googl, zeiger, physician, never, report, pote...          google   \n",
       "9091  [verizon, iphon, custom, complain, time, fell,...           apple   \n",
       "9092  [ûârt, mention, googl, test, ûïcheck, offer, s...          google   \n",
       "\n",
       "     predict_directed   predict_emotion  positive  negative  predict_positive  \\\n",
       "0              iphone  Negative emotion         0         1                 0   \n",
       "1                 app  Positive emotion         1         0                 1   \n",
       "2                ipad  Positive emotion         1         0                 1   \n",
       "3                 app              None         0         1                 0   \n",
       "4              google  Positive emotion         1         0                 1   \n",
       "...               ...               ...       ...       ...               ...   \n",
       "9088             ipad              None         1         0                 0   \n",
       "9089           google              None         0         0                 0   \n",
       "9090           google              None         0         0                 0   \n",
       "9091           iphone              None         0         0                 0   \n",
       "9092           google              None         0         0                 0   \n",
       "\n",
       "      predict_negative  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "9088                 0  \n",
       "9089                 0  \n",
       "9090                 0  \n",
       "9091                 0  \n",
       "9092                 0  \n",
       "\n",
       "[9092 rows x 11 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipad everywhere. #SXSW {link}\n",
      "Positive emotion\n",
      "@mention  - Great weather to greet you for #sxsw! Still need a sweater at night..Apple putting up &quot;flash store&quot; downtown to sell iPad2\n",
      "Positive emotion\n"
     ]
    }
   ],
   "source": [
    "#checks how many tweets are retweets (a tweet was reposted by another user). \n",
    "#There were 2677 retweets\n",
    "len([row for row in df[\"tweet_text\"] if \"RT\" in row])\n",
    "\n",
    "#I think this tweet is interesting as its marked as positive but feels like it could be either\n",
    "print(df['tweet_text'][9088])\n",
    "print(df['is_there_an_emotion_directed_at_a_brand_or_product'][9088])\n",
    "#or like this tweet where its marked as positive but its just remarking on the weather\n",
    "print(df[\"tweet_text\"][40])\n",
    "print(df['is_there_an_emotion_directed_at_a_brand_or_product'][40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aapl</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarpbulletin</th>\n",
       "      <th>ab</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abba</th>\n",
       "      <th>abc</th>\n",
       "      <th>aber</th>\n",
       "      <th>abilities</th>\n",
       "      <th>...</th>\n",
       "      <th>zms</th>\n",
       "      <th>zomb</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zynga</th>\n",
       "      <th>zzzs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9092 rows × 9284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aapl  aaron  aarpbulletin  ab  abacus  abandoned  abba  abc  aber  \\\n",
       "0        0      0             0   0       0          0     0    0     0   \n",
       "1        0      0             0   0       0          0     0    0     0   \n",
       "2        0      0             0   0       0          0     0    0     0   \n",
       "3        0      0             0   0       0          0     0    0     0   \n",
       "4        0      0             0   0       0          0     0    0     0   \n",
       "...    ...    ...           ...  ..     ...        ...   ...  ...   ...   \n",
       "9087     0      0             0   0       0          0     0    0     0   \n",
       "9088     0      0             0   0       0          0     0    0     0   \n",
       "9089     0      0             0   0       0          0     0    0     0   \n",
       "9090     0      0             0   0       0          0     0    0     0   \n",
       "9091     0      0             0   0       0          0     0    0     0   \n",
       "\n",
       "      abilities  ...  zms  zomb  zombie  zombies  zomg  zone  zoom  \\\n",
       "0             0  ...    0     0       0        0     0     0     0   \n",
       "1             0  ...    0     0       0        0     0     0     0   \n",
       "2             0  ...    0     0       0        0     0     0     0   \n",
       "3             0  ...    0     0       0        0     0     0     0   \n",
       "4             0  ...    0     0       0        0     0     0     0   \n",
       "...         ...  ...  ...   ...     ...      ...   ...   ...   ...   \n",
       "9087          0  ...    0     0       0        0     0     0     0   \n",
       "9088          0  ...    0     0       0        0     0     0     0   \n",
       "9089          0  ...    0     0       0        0     0     0     0   \n",
       "9090          0  ...    0     0       0        0     0     0     0   \n",
       "9091          0  ...    0     0       0        0     0     0     0   \n",
       "\n",
       "      zuckerberg  zynga  zzzs  \n",
       "0              0      0     0  \n",
       "1              0      0     0  \n",
       "2              0      0     0  \n",
       "3              0      0     0  \n",
       "4              0      0     0  \n",
       "...          ...    ...   ...  \n",
       "9087           0      0     0  \n",
       "9088           0      0     0  \n",
       "9089           0      0     0  \n",
       "9090           0      0     0  \n",
       "9091           0      0     0  \n",
       "\n",
       "[9092 rows x 9284 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "for row in df[\"tweet_text\"]:\n",
    "    corpus += [row + \",\"]\n",
    "\n",
    "vec = CountVectorizer(token_pattern=r\"([a-zA-Z]+(?:'[a-z]+)?)\", stop_words=stopwords.words(\"english\"))\n",
    "X = vec.fit_transform(corpus)\n",
    "df_cv = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'new': 688,\n",
       " 'ipad': 1347,\n",
       " 'app': 477,\n",
       " 'sxsw': 5898,\n",
       " 'itun': 71,\n",
       " 'store': 918,\n",
       " 'via': 290,\n",
       " 'mention': 4624,\n",
       " 'see': 150,\n",
       " 'android': 365,\n",
       " 'link': 3002,\n",
       " 'anyon': 94,\n",
       " 'want': 107,\n",
       " 'sell': 55,\n",
       " 'googl': 1784,\n",
       " 'launch': 612,\n",
       " 'major': 235,\n",
       " 'social': 513,\n",
       " 'network': 377,\n",
       " 'call': 313,\n",
       " 'circl': 529,\n",
       " 'possibl': 202,\n",
       " 'today': 449,\n",
       " 'play': 53,\n",
       " 'music': 113,\n",
       " 'amp': 603,\n",
       " 'com': 63,\n",
       " 'appl': 1280,\n",
       " 'mobil': 239,\n",
       " 'updat': 73,\n",
       " 'iphon': 879,\n",
       " 'blackberri': 69,\n",
       " 'get': 291,\n",
       " 'friend': 57,\n",
       " 'hey': 61,\n",
       " 'think': 107,\n",
       " 'take': 75,\n",
       " 'make': 147,\n",
       " 'case': 63,\n",
       " 'use': 156,\n",
       " 'one': 147,\n",
       " 'video': 75,\n",
       " 'includ': 73,\n",
       " 'set': 128,\n",
       " 'say': 120,\n",
       " 'quot': 1062,\n",
       " 'platform': 56,\n",
       " 'help': 57,\n",
       " 'sxswi': 234,\n",
       " 'locat': 108,\n",
       " 'futur': 69,\n",
       " 'connect': 56,\n",
       " 'digit': 67,\n",
       " 'world': 54,\n",
       " 'tweet': 102,\n",
       " 'panel': 105,\n",
       " 'check': 193,\n",
       " 'guy': 105,\n",
       " 'talk': 131,\n",
       " 'know': 140,\n",
       " 'search': 109,\n",
       " 'pop': 377,\n",
       " 'austin': 651,\n",
       " 'would': 68,\n",
       " 'interest': 51,\n",
       " 'wait': 64,\n",
       " 'buy': 68,\n",
       " 'join': 55,\n",
       " 'give': 77,\n",
       " 'need': 146,\n",
       " 'win': 156,\n",
       " 'best': 72,\n",
       " 'news': 96,\n",
       " 'last': 79,\n",
       " 'ipad2': 244,\n",
       " 'follow': 57,\n",
       " 'open': 344,\n",
       " 'popup': 133,\n",
       " 'downtown': 136,\n",
       " 'thank': 78,\n",
       " 'parti': 246,\n",
       " 'tri': 58,\n",
       " 'japan': 84,\n",
       " 'got': 79,\n",
       " 'free': 262,\n",
       " 'tonight': 58,\n",
       " 'attend': 54,\n",
       " 'right': 71,\n",
       " 'day': 138,\n",
       " 'head': 80,\n",
       " 'map': 147,\n",
       " 'twitter': 72,\n",
       " 'good': 69,\n",
       " 'download': 100,\n",
       " 'meet': 55,\n",
       " 'interact': 53,\n",
       " 'time': 147,\n",
       " 'event': 79,\n",
       " 'line': 290,\n",
       " 'come': 170,\n",
       " 'work': 65,\n",
       " 'game': 104,\n",
       " 'develop': 72,\n",
       " 'look': 117,\n",
       " 'let': 65,\n",
       " 'great': 77,\n",
       " 'marissa': 126,\n",
       " 'mayer': 140,\n",
       " 'year': 82,\n",
       " 'user': 73,\n",
       " 'peopl': 119,\n",
       " 'love': 54,\n",
       " 'post': 57,\n",
       " 'way': 52,\n",
       " 'facebook': 83,\n",
       " '6th': 72,\n",
       " 'week': 59,\n",
       " 'go': 140,\n",
       " 'show': 123,\n",
       " 'temporari': 172,\n",
       " 'photo': 60,\n",
       " 'team': 56,\n",
       " 'phone': 62,\n",
       " 'first': 93,\n",
       " 'still': 56,\n",
       " 'tech': 94,\n",
       " 'congress': 76,\n",
       " 'around': 60,\n",
       " 'find': 69,\n",
       " 'product': 115,\n",
       " 'shop': 93,\n",
       " 'like': 166,\n",
       " 'geek': 51,\n",
       " 'big': 84,\n",
       " 'live': 62,\n",
       " 'booth': 74,\n",
       " 'session': 74,\n",
       " 'design': 152,\n",
       " 'thing': 62,\n",
       " 'rumor': 109,\n",
       " 'next': 84,\n",
       " 'start': 69,\n",
       " 'pleas': 58,\n",
       " 'present': 62,\n",
       " 'bing': 82,\n",
       " 'featur': 53,\n",
       " 'rank': 53,\n",
       " 'code': 76}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_wordcount = {}\n",
    "for row in (df.loc[df['is_there_an_emotion_directed_at_a_brand_or_product'] == \"No emotion toward brand or product\"]\n",
    "            [\"preprocessed_text\"]):\n",
    "    for word in row:\n",
    "        if word in neutral_wordcount:\n",
    "            neutral_wordcount[word] += 1\n",
    "        else:\n",
    "            neutral_wordcount[word] = 1\n",
    "for row in (df.loc[df['is_there_an_emotion_directed_at_a_brand_or_product'] == \"I can't tell\"][\"preprocessed_text\"]):\n",
    "    for word in row:\n",
    "        if word in neutral_wordcount:\n",
    "            neutral_wordcount[word] += 1\n",
    "        else:\n",
    "            neutral_wordcount[word] = 1\n",
    "\n",
    "            \n",
    "for key in list(neutral_wordcount.keys()):\n",
    "    if neutral_wordcount[key] < 50:\n",
    "        del neutral_wordcount[key]\n",
    "\n",
    "print(len(neutral_wordcount))\n",
    "neutral_wordcount"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

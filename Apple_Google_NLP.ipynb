{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding the responses of products displayed at South by South West (SXSW) and seeing which product was seen to be the most favorable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Data Read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in tweets from data, about 9000 rows and three columns\n",
    "df = pd.read_csv(\"data/twitter_data.csv\", encoding=\"unicode_escape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropped one tweet that had a NA value (row 6)\n",
    "df = df.loc[df[\"tweet_text\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-85-a035a0678c57>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"preprocessed_text\"] = [preprocess_text(tweet) for tweet in df[\"tweet_text\"]]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = RegexpTokenizer(r\"(?u)\\w{3,}\").tokenize(tweet)\n",
    "    tweet = [word for word in tweet if word not in stopwords.words(\"english\")]\n",
    "    tweet = [PorterStemmer().stem(word) for word in tweet]\n",
    "    return tweet\n",
    "\n",
    "df[\"preprocessed_text\"] = [preprocess_text(tweet) for tweet in df[\"tweet_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-86-d69cf1630b3f>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"predict_company\"] = [company(tweet) for tweet in df[\"preprocessed_text\"]]\n"
     ]
    }
   ],
   "source": [
    "def company(tweet):\n",
    "    if \"appl\" in tweet or \"iphon\" in tweet or \"ipad\" in tweet:\n",
    "        return \"apple\"\n",
    "    elif \"googl\" in tweet or \"android\" in tweet:\n",
    "        return \"google\"\n",
    "\n",
    "df[\"predict_company\"] = [company(tweet) for tweet in df[\"preprocessed_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-87-d7088b5526de>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"predict_directed\"] = [directed_at(tweet) for tweet in df[\"preprocessed_text\"]]\n"
     ]
    }
   ],
   "source": [
    "def directed_at(tweet):\n",
    "    if \"app\" in tweet:\n",
    "        return \"app\"\n",
    "    elif \"ipad\" in tweet:\n",
    "        return \"ipad\"\n",
    "    elif \"iphon\" in tweet:\n",
    "        return \"iphone\"\n",
    "    elif \"android\" in tweet:\n",
    "        return \"android\"\n",
    "    elif \"googl\" in tweet:\n",
    "        return \"google\"\n",
    "\n",
    "df[\"predict_directed\"] = [directed_at(tweet) for tweet in df[\"preprocessed_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apple     5477\n",
       "google    2783\n",
       "Name: predict_company, dtype: int64"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"predict_company\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-284-104e59c5249b>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"predict_emotion\"] = [emotion(tweet) for tweet in df[\"preprocessed_text\"]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Positive emotion    1865\n",
       "Negative emotion      54\n",
       "Name: predict_emotion, dtype: int64"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emotion(tweet):\n",
    "    if (\"great\" in tweet or \"awesome\" in tweet or \"like\" in tweet or \"appreci\" in tweet or \"good\" in tweet \n",
    "            or \"beauti\" in tweet or \"smart\" in tweet or \"excit\" in tweet or \"wait\" in tweet or \"best\" in tweet\n",
    "            or \"love\" in tweet or \"nice\" in tweet or \"must\" in tweet or \"need\" in tweet or \"enjoy\" in tweet\n",
    "            or \"rock\" in tweet or \"best\" in tweet or \"win\" in tweet or \"\" in tweet): #maybe \"launch\" or \"open\" or \"check\"\n",
    "        return \"Positive emotion\"\n",
    "    elif (\"dead\" in tweet or \"insan\" in tweet or \"headach\" in tweet):\n",
    "        return \"Negative emotion\"\n",
    "df[\"predict_emotion\"] = [emotion(tweet) for tweet in df[\"preprocessed_text\"]]\n",
    "df[\"predict_emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holla! RT @mention At google party. Best ever! Get your butt over here. #sxsw\n",
      "['holla', 'mention', 'googl', 'parti', 'best', 'ever', 'get', 'butt', 'sxsw']\n",
      "Positive emotion\n"
     ]
    }
   ],
   "source": [
    "print(df[\"tweet_text\"][75])\n",
    "print(df['preprocessed_text'][75])\n",
    "print(df['is_there_an_emotion_directed_at_a_brand_or_product'][75])\n",
    "#print(df[\"emotion_in_tweet_is_directed_at\"][17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>predict_company</th>\n",
       "      <th>predict_directed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[wesley83, iphon, hr, tweet, rise_austin, dead...</td>\n",
       "      <td>apple</td>\n",
       "      <td>iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[jessede, know, fludapp, awesom, ipad, iphon, ...</td>\n",
       "      <td>apple</td>\n",
       "      <td>app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[swonderlin, wait, ipad, also, sale, sxsw]</td>\n",
       "      <td>apple</td>\n",
       "      <td>ipad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[sxsw, hope, year, festiv, crashi, year, iphon...</td>\n",
       "      <td>apple</td>\n",
       "      <td>app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[sxtxstate, great, stuff, fri, sxsw, marissa, ...</td>\n",
       "      <td>google</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[ipad, everywher, sxsw, link]</td>\n",
       "      <td>apple</td>\n",
       "      <td>ipad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[wave, buzz, mention, interrupt, regularli, sc...</td>\n",
       "      <td>google</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[googl, zeiger, physician, never, report, pote...</td>\n",
       "      <td>google</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[verizon, iphon, custom, complain, time, fell,...</td>\n",
       "      <td>apple</td>\n",
       "      <td>iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[ûârt, mention, googl, test, ûïcheck, offer, s...</td>\n",
       "      <td>google</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9092 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0                                      Negative emotion   \n",
       "1                                      Positive emotion   \n",
       "2                                      Positive emotion   \n",
       "3                                      Negative emotion   \n",
       "4                                      Positive emotion   \n",
       "...                                                 ...   \n",
       "9088                                   Positive emotion   \n",
       "9089                 No emotion toward brand or product   \n",
       "9090                 No emotion toward brand or product   \n",
       "9091                 No emotion toward brand or product   \n",
       "9092                 No emotion toward brand or product   \n",
       "\n",
       "                                      preprocessed_text predict_company  \\\n",
       "0     [wesley83, iphon, hr, tweet, rise_austin, dead...           apple   \n",
       "1     [jessede, know, fludapp, awesom, ipad, iphon, ...           apple   \n",
       "2            [swonderlin, wait, ipad, also, sale, sxsw]           apple   \n",
       "3     [sxsw, hope, year, festiv, crashi, year, iphon...           apple   \n",
       "4     [sxtxstate, great, stuff, fri, sxsw, marissa, ...          google   \n",
       "...                                                 ...             ...   \n",
       "9088                      [ipad, everywher, sxsw, link]           apple   \n",
       "9089  [wave, buzz, mention, interrupt, regularli, sc...          google   \n",
       "9090  [googl, zeiger, physician, never, report, pote...          google   \n",
       "9091  [verizon, iphon, custom, complain, time, fell,...           apple   \n",
       "9092  [ûârt, mention, googl, test, ûïcheck, offer, s...          google   \n",
       "\n",
       "     predict_directed  \n",
       "0              iphone  \n",
       "1                 app  \n",
       "2                ipad  \n",
       "3                 app  \n",
       "4                None  \n",
       "...               ...  \n",
       "9088             ipad  \n",
       "9089             None  \n",
       "9090             None  \n",
       "9091           iphone  \n",
       "9092             None  \n",
       "\n",
       "[9092 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad                               946\n",
       "Apple                              661\n",
       "iPad or iPhone App                 470\n",
       "Google                             430\n",
       "iPhone                             297\n",
       "Other Google product or service    293\n",
       "Android App                         81\n",
       "Android                             78\n",
       "Other Apple product or service      35\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"emotion_in_tweet_is_directed_at\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     5801\n",
       "False    3291\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"emotion_in_tweet_is_directed_at\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    6810\n",
       "True     2282\n",
       "Name: predict_directed, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"predict_directed\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipad everywhere. #SXSW {link}\n",
      "Positive emotion\n",
      "@mention  - Great weather to greet you for #sxsw! Still need a sweater at night..Apple putting up &quot;flash store&quot; downtown to sell iPad2\n",
      "Positive emotion\n"
     ]
    }
   ],
   "source": [
    "#checks how many tweets are retweets (a tweet was reposted by another user). \n",
    "#There were 2677 retweets\n",
    "len([row for row in df[\"tweet_text\"] if \"RT\" in row])\n",
    "\n",
    "#I think this tweet is interesting as its marked as positive but feels like it could be either\n",
    "print(df['tweet_text'][9088])\n",
    "print(df['is_there_an_emotion_directed_at_a_brand_or_product'][9088])\n",
    "#or like this tweet where its marked as positive but its just remarking on the weather\n",
    "print(df[\"tweet_text\"][40])\n",
    "print(df['is_there_an_emotion_directed_at_a_brand_or_product'][40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aapl</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarpbulletin</th>\n",
       "      <th>ab</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abba</th>\n",
       "      <th>abc</th>\n",
       "      <th>aber</th>\n",
       "      <th>abilities</th>\n",
       "      <th>...</th>\n",
       "      <th>zms</th>\n",
       "      <th>zomb</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zynga</th>\n",
       "      <th>zzzs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9092 rows × 9284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aapl  aaron  aarpbulletin  ab  abacus  abandoned  abba  abc  aber  \\\n",
       "0        0      0             0   0       0          0     0    0     0   \n",
       "1        0      0             0   0       0          0     0    0     0   \n",
       "2        0      0             0   0       0          0     0    0     0   \n",
       "3        0      0             0   0       0          0     0    0     0   \n",
       "4        0      0             0   0       0          0     0    0     0   \n",
       "...    ...    ...           ...  ..     ...        ...   ...  ...   ...   \n",
       "9087     0      0             0   0       0          0     0    0     0   \n",
       "9088     0      0             0   0       0          0     0    0     0   \n",
       "9089     0      0             0   0       0          0     0    0     0   \n",
       "9090     0      0             0   0       0          0     0    0     0   \n",
       "9091     0      0             0   0       0          0     0    0     0   \n",
       "\n",
       "      abilities  ...  zms  zomb  zombie  zombies  zomg  zone  zoom  \\\n",
       "0             0  ...    0     0       0        0     0     0     0   \n",
       "1             0  ...    0     0       0        0     0     0     0   \n",
       "2             0  ...    0     0       0        0     0     0     0   \n",
       "3             0  ...    0     0       0        0     0     0     0   \n",
       "4             0  ...    0     0       0        0     0     0     0   \n",
       "...         ...  ...  ...   ...     ...      ...   ...   ...   ...   \n",
       "9087          0  ...    0     0       0        0     0     0     0   \n",
       "9088          0  ...    0     0       0        0     0     0     0   \n",
       "9089          0  ...    0     0       0        0     0     0     0   \n",
       "9090          0  ...    0     0       0        0     0     0     0   \n",
       "9091          0  ...    0     0       0        0     0     0     0   \n",
       "\n",
       "      zuckerberg  zynga  zzzs  \n",
       "0              0      0     0  \n",
       "1              0      0     0  \n",
       "2              0      0     0  \n",
       "3              0      0     0  \n",
       "4              0      0     0  \n",
       "...          ...    ...   ...  \n",
       "9087           0      0     0  \n",
       "9088           0      0     0  \n",
       "9089           0      0     0  \n",
       "9090           0      0     0  \n",
       "9091           0      0     0  \n",
       "\n",
       "[9092 rows x 9284 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "for row in df[\"tweet_text\"]:\n",
    "    corpus += [row + \",\"]\n",
    "\n",
    "vec = CountVectorizer(token_pattern=r\"([a-zA-Z]+(?:'[a-z]+)?)\", stop_words=stopwords.words(\"english\"))\n",
    "X = vec.fit_transform(corpus)\n",
    "df_cv = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
